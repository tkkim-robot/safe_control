#!/usr/bin/env python3
"""
Train BarrierNet models from datasets generated by `generate_dataset.py`.

Dataset files expected:
  safe_control/position_control/BarrierNet/data/<ROBOT_MODEL>_data_{train,valid,test}.mat
Each contains 'data' matrix with rows [z, ctx, u_ref, u*].

Important: training calls BarrierNet with sgn=1 (no input bounds inside QP).
"""

from __future__ import annotations

import json
import os
import sys
import warnings
import numpy as np
import scipy.io as sio
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, Dataset

_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "..", ".."))
if _ROOT not in sys.path:
    sys.path.insert(0, _ROOT)

from safe_control.position_control.BarrierNet.models import BarrierNet, ROBOT_CFG


# =========================
# CONFIG (edit in code)
# =========================
ROBOT_MODEL = os.environ.get(
    "BN_ROBOT_MODEL",
    "DynamicUnicycle2D",
)  # DynamicUnicycle2D, Quad2D, Quad3D, KinematicBicycle2D_DPCBF
EPOCHS = int(os.environ.get("BN_EPOCHS", "50"))
BATCH_SIZE = int(os.environ.get("BN_BATCH_SIZE", "64"))
LR = float(os.environ.get("BN_LR", "1e-3"))
DEVICE = os.environ.get("BN_DEVICE", "auto")  # auto/cpu/cuda

DATA_DIR = os.path.join(os.path.dirname(__file__), "data")
CKPT_DIR = os.path.join(os.path.dirname(__file__), "checkpoints")


class MatDataset(Dataset):
    """BarrierNet dataset: [z, ctx, u_ref, u*]"""
    def __init__(self, z: np.ndarray, ctx: np.ndarray, u_ref: np.ndarray, y: np.ndarray):
        self.z = torch.from_numpy(z).double()
        self.ctx = torch.from_numpy(ctx).double()
        self.u_ref = torch.from_numpy(u_ref).double()
        self.y = torch.from_numpy(y).double()

    def __len__(self):
        return self.z.shape[0]

    def __getitem__(self, idx):
        return self.z[idx], self.ctx[idx], self.u_ref[idx], self.y[idx]


def load_split(robot_model: str, split: str) -> np.ndarray:
    path = os.path.join(DATA_DIR, f"{robot_model}_data_{split}.mat")
    if not os.path.exists(path):
        raise FileNotFoundError(path)
    return sio.loadmat(path)["data"].astype(np.float64)


def main():
    os.makedirs(CKPT_DIR, exist_ok=True)

    spec = ROBOT_CFG[ROBOT_MODEL]
    train = load_split(ROBOT_MODEL, "train")
    valid = load_split(ROBOT_MODEL, "valid")

    z_dim = spec.z_dim
    ctx_dim = spec.ctx_dim
    n_u = spec.n_u

    # Dataset format: [z, ctx, u_ref, u*]
    z_train = train[:, :z_dim]
    ctx_train = train[:, z_dim : z_dim + ctx_dim]
    u_ref_train = train[:, z_dim + ctx_dim : z_dim + ctx_dim + n_u]
    y_train = train[:, z_dim + ctx_dim + n_u : z_dim + ctx_dim + n_u + n_u]

    z_valid = valid[:, :z_dim]
    ctx_valid = valid[:, z_dim : z_dim + ctx_dim]
    u_ref_valid = valid[:, z_dim + ctx_dim : z_dim + ctx_dim + n_u]
    y_valid = valid[:, z_dim + ctx_dim + n_u : z_dim + ctx_dim + n_u + n_u]

    # Normalization: z only (neural input), ctx stays raw
    mean = z_train.mean(axis=0)
    std = z_train.std(axis=0)
    std[std == 0] = 1.0

    z_train_n = (z_train - mean) / std
    z_valid_n = (z_valid - mean) / std

    if DEVICE == "auto":
        # Prefer CPU for dQP training stability (pivoting enabled in qpth LU factorization).
        device = torch.device("cpu")
    else:
        device = torch.device(DEVICE)

    model = BarrierNet(ROBOT_MODEL, mean=mean, std=std, device=device).to(device)
    model.train()

    opt = torch.optim.Adam(model.parameters(), lr=LR)
    loss_fn = nn.MSELoss()

    train_loader = DataLoader(
        MatDataset(z_train_n, ctx_train, u_ref_train, y_train),
        batch_size=BATCH_SIZE,
        shuffle=True,
        num_workers=0
    )
    valid_loader = DataLoader(
        MatDataset(z_valid_n, ctx_valid, u_ref_valid, y_valid),
        batch_size=BATCH_SIZE,
        shuffle=False,
        num_workers=0
    )

    best_val = float("inf")
    for ep in range(EPOCHS):
        model.train()
        tr_losses = []
        for zb, ctxb, u_refb, yb in train_loader:
            zb = zb.to(device)
            ctxb = ctxb.to(device)
            u_refb = u_refb.to(device)
            yb = yb.to(device)
            pred = model(zb, ctxb, u_refb, sgn=1)  # forward(z_norm, ctx, u_ref, sgn)
            loss = loss_fn(pred, yb)
            opt.zero_grad()
            loss.backward()
            opt.step()
            tr_losses.append(loss.item())

        model.eval()
        with torch.no_grad():
            val_losses = []
            for zb, ctxb, u_refb, yb in valid_loader:
                zb = zb.to(device)
                ctxb = ctxb.to(device)
                u_refb = u_refb.to(device)
                yb = yb.to(device)
                pred = model(zb, ctxb, u_refb, sgn=1)
                val_losses.append(loss_fn(pred, yb).item())
            val = float(np.mean(val_losses)) if val_losses else float("inf")

        tr = float(np.mean(tr_losses)) if tr_losses else float("inf")
        print(f"epoch {ep+1}/{EPOCHS} train={tr:.6f} valid={val:.6f}")
        if val < best_val:
            best_val = val
            ckpt_path = os.path.join(CKPT_DIR, f"{ROBOT_MODEL}_barriernet.pth")
            meta_path = ckpt_path.replace(".pth", "_meta.json")
            torch.save(model.state_dict(), ckpt_path)
            meta = {
                "robot_model": ROBOT_MODEL,
                "mean": mean.tolist(),
                "std": std.tolist(),
                "robot_radius": float(model.robot_radius),
                "spec": {
                    "z_dim": spec.z_dim,
                    "ctx_dim": spec.ctx_dim,
                    "n_u": spec.n_u,
                    "k_obs": spec.k_obs,
                    "relative_degree": spec.relative_degree,
                    "hidden_sizes": spec.hidden_sizes,
                    "activation": spec.activation,
                    "extra_layers": spec.extra_layers,
                    "control_bounds": spec.control_bounds,
                    "robot_radius_default": spec.robot_radius_default,
                },
            }
            with open(meta_path, "w") as f:
                json.dump(meta, f, indent=2)
            print(f"  saved: {ckpt_path} (best valid={best_val:.6f})")


if __name__ == "__main__":
    main()


