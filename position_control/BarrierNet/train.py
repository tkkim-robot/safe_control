#!/usr/bin/env python3
"""
Train BarrierNet models from datasets generated by `generate_dataset.py`.

Dataset files expected:
  safe_control/position_control/BarrierNet/data/<ROBOT_MODEL>_data_{train,valid,test}.mat
Each contains 'data' matrix with rows [features..., labels...].

Important: training calls BarrierNet with sgn=1 (no input bounds inside QP).
"""

from __future__ import annotations

import json
import os
import sys
import numpy as np
import scipy.io as sio
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, Dataset

# Ensure *parent of safe_control* is on PYTHONPATH so `import safe_control` works
# both when:
# - online_adaptive_cbf imports safe_control as a subrepo, and
# - user runs scripts from inside the safe_control repo.
_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "..", ".."))
if _ROOT not in sys.path:
    sys.path.insert(0, _ROOT)

from safe_control.position_control.BarrierNet.models import BarrierNet, ROBOT_CFG


# =========================
# CONFIG (edit in code)
# =========================
ROBOT_MODEL = os.environ.get(
    "BN_ROBOT_MODEL",
    "DynamicUnicycle2D",
)  # DynamicUnicycle2D, Quad2D, Quad3D, KinematicBicycle2D_DPCBF
EPOCHS = int(os.environ.get("BN_EPOCHS", "10"))
BATCH_SIZE = int(os.environ.get("BN_BATCH_SIZE", "64"))
LR = float(os.environ.get("BN_LR", "1e-3"))
DEVICE = os.environ.get("BN_DEVICE", "auto")  # auto/cpu/cuda

DATA_DIR = os.path.join(os.path.dirname(__file__), "data")
CKPT_DIR = os.path.join(os.path.dirname(__file__), "checkpoints")


class MatDataset(Dataset):
    def __init__(self, z: np.ndarray, ctx: np.ndarray, u_ref: np.ndarray, y: np.ndarray):
        self.z = torch.from_numpy(z).double()
        self.ctx = torch.from_numpy(ctx).double()
        self.u_ref = torch.from_numpy(u_ref).double()
        self.y = torch.from_numpy(y).double()

    def __len__(self):
        return self.z.shape[0]

    def __getitem__(self, idx):
        return self.z[idx], self.ctx[idx], self.u_ref[idx], self.y[idx]


def load_split(robot_model: str, split: str) -> np.ndarray:
    path = os.path.join(DATA_DIR, f"{robot_model}_data_{split}.mat")
    if not os.path.exists(path):
        raise FileNotFoundError(path)
    return sio.loadmat(path)["data"].astype(np.float64)


def main():
    os.makedirs(CKPT_DIR, exist_ok=True)

    spec = ROBOT_CFG[ROBOT_MODEL]
    train = load_split(ROBOT_MODEL, "train")
    valid = load_split(ROBOT_MODEL, "valid")

    n_z = spec.z_dim
    n_ctx = spec.ctx_dim
    n_u = spec.n_u

    z_train = train[:, :n_z]
    ctx_train = train[:, n_z : n_z + n_ctx]
    uref_train = train[:, n_z + n_ctx : n_z + n_ctx + n_u]
    y_train = train[:, n_z + n_ctx + n_u : n_z + n_ctx + n_u + n_u]

    z_valid = valid[:, :n_z]
    ctx_valid = valid[:, n_z : n_z + n_ctx]
    uref_valid = valid[:, n_z + n_ctx : n_z + n_ctx + n_u]
    y_valid = valid[:, n_z + n_ctx + n_u : n_z + n_ctx + n_u + n_u]

    mean = z_train.mean(axis=0)
    std = z_train.std(axis=0)
    std[std == 0] = 1.0

    z_train_n = (z_train - mean) / std
    z_valid_n = (z_valid - mean) / std

    if DEVICE == "auto":
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    else:
        device = torch.device(DEVICE)

    model = BarrierNet(ROBOT_MODEL, mean=mean, std=std, device=device).to(device)
    model.train()

    # propagate runtime parameters from spec (can be overridden by deployment controller)
    model.set_robot_radius(spec.robot_radius_default)
    if ROBOT_MODEL == "KinematicBicycle2D_DPCBF":
        model.set_rear_ax_dist(0.2)

    opt = torch.optim.Adam(model.parameters(), lr=LR)
    loss_fn = nn.MSELoss()

    train_loader = DataLoader(MatDataset(z_train_n, ctx_train, uref_train, y_train), batch_size=BATCH_SIZE, shuffle=True, num_workers=0)
    valid_loader = DataLoader(MatDataset(z_valid_n, ctx_valid, uref_valid, y_valid), batch_size=BATCH_SIZE, shuffle=False, num_workers=0)

    best_val = float("inf")
    for ep in range(EPOCHS):
        model.train()
        tr_losses = []
        for zb, ctxb, urefb, yb in train_loader:
            zb = zb.to(device)
            ctxb = ctxb.to(device)
            urefb = urefb.to(device)
            yb = yb.to(device)
            pred = model(zb, ctxb, urefb, sgn=1)  # sgn=1 => training mode (no input bounds)
            loss = loss_fn(pred, yb)
            opt.zero_grad()
            loss.backward()
            opt.step()
            tr_losses.append(loss.item())

        model.eval()
        with torch.no_grad():
            val_losses = []
            for zb, ctxb, urefb, yb in valid_loader:
                zb = zb.to(device)
                ctxb = ctxb.to(device)
                urefb = urefb.to(device)
                yb = yb.to(device)
                pred = model(zb, ctxb, urefb, sgn=1)  # keep differentiable QP in eval during training
                val_losses.append(loss_fn(pred, yb).item())
            val = float(np.mean(val_losses)) if val_losses else float("inf")

        tr = float(np.mean(tr_losses)) if tr_losses else float("inf")
        print(f"epoch {ep+1}/{EPOCHS} train={tr:.6f} valid={val:.6f}")
        if val < best_val:
            best_val = val
            ckpt_path = os.path.join(CKPT_DIR, f"{ROBOT_MODEL}_barriernet.pth")
            meta_path = ckpt_path.replace(".pth", "_meta.json")
            torch.save(model.state_dict(), ckpt_path)
            meta = {
                "robot_model": ROBOT_MODEL,
                "mean": mean.tolist(),
                "std": std.tolist(),
                "robot_radius": float(model.robot_radius),
                "spec": {
                    "family": spec.family,
                    "state_dim": spec.state_dim,
                    "goal_dim": spec.goal_dim,
                    "obs_dim": spec.obs_dim,
                    "k_obs": spec.k_obs,
                    "z_block_dim": spec.z_block_dim,
                    "z_dim": spec.z_dim,
                    "ctx_dim": spec.ctx_dim,
                    "n_u": spec.n_u,
                    "relative_degree": spec.relative_degree,
                },
            }
            with open(meta_path, "w") as f:
                json.dump(meta, f)
            print(f"  saved: {ckpt_path} (best valid={best_val:.6f})")


if __name__ == "__main__":
    main()


